{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of a Generative Adversarial Network\n",
    "\n",
    "\n",
    "This notebook provides an example on how to build and train an adversarial generative network (GAN) for fast simulation of shower images produced by a high energy physics calorimeter detector. \n",
    "\n",
    "For this example we are using 2d projection in the transverse and longitudinal plane of 3d shower profiles of an high granularity electromagnetic calorimeter. The calorimeter is a prototype detector which has been studied for for a future linear collider experiment (CLIC).   \n",
    "\n",
    "Using as input data obtained from full simulation of the detector we train a GAN with the aim to perform a fast simulation of the calorimeter. \n",
    "\n",
    "A detailed explanation on the original study using GAN for fast  is available in this publication:\n",
    "\n",
    "*F. Carminati, A. Gheata, K. Gulrukh, P. Mendez Lorenzo, S. Sharan, S. Vallecorsa, Three dimensional Generative Adversarial Networks for fast simulation. Journal of Physics: Conference Series. 1085. 032016. 10.1088/1742-6596/1085/3/032016*\n",
    "\n",
    "Here for simplicity and faster numerical computation, we are using a 2d propjection of the data and train a GAN consisting of 2d convolutional layer to re-generate this data. \n",
    "\n",
    "We provide in the notebook an example how to train the GAN, then how to generate events using a trained network model and we show also the comparison of the obtained showers with the original full simulated ones \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "import h5py \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# for having interactive plots\n",
    "%matplotlib notebook\n",
    "\n",
    "#options for GPU running\n",
    "import tensorflow as tf\n",
    "session_config = tf.ConfigProto(log_device_placement=True)\n",
    "session_config.gpu_options.allow_growth=True\n",
    "session = tf.Session(config=session_config)\n",
    "K.set_session(session)\n",
    "\n",
    "#use theano (th) like image ordering :   color x width x height \n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adadelta, Adam, RMSprop\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import (Input, InputLayer, Dense, Reshape, Flatten, Lambda, merge,\n",
    "                          Dropout, BatchNormalization, Activation, Embedding)\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import (UpSampling2D, Conv2D, ZeroPadding2D,\n",
    "                                        AveragePooling2D)\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define common parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define here some gloabl parameter for the example such as: \n",
    "\n",
    "* number of epochs used for training\n",
    "* batch size\n",
    "* size of the latent input (i.e. the input random data used for generating then the images)\n",
    "* total number of events used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 10\n",
    "batch_size = 1000\n",
    "latent_size = 100\n",
    "nevt = 10000  # number of events used for (training and testing)\n",
    "train_event_rate = 0.9    # rate of all events used for training, the rest will be used for testing the model\n",
    "\n",
    "seed = None      #seed used for splitting the data (use None for having different one)\n",
    "flip_rate = 0.05  #  rate used to flip  fake/real simulated data labels in the discriminator\n",
    "\n",
    "\n",
    "load_initial_weights = False # start training from an initial set of weights\n",
    "# input name for the weights used for loading the initial model configuration when load_initial_weigts=True \n",
    "input_weights = \"weights_epoch_100\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build GAN model\n",
    "\n",
    "We build now the different components (discriminator and generator) for a generative adversarial model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create discriminator model\n",
    "\n",
    "We create first the discriminator model using Keras sequential model building.\n",
    "The model consists of 4 convolutional layer followd by a pooling layer and then a dense layer with a single output to discriminate real images from fake ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Sequential(name='discriminator')\n",
    "\n",
    "d.add(Conv2D(32, (5,5), data_format='channels_first', padding='same', input_shape=(1,25,25) ) ) \n",
    "d.add(LeakyReLU())\n",
    "d.add(ZeroPadding2D((2,2)) )\n",
    "\n",
    "d.add(Conv2D(8, (5, 5), data_format='channels_first', padding='valid'))\n",
    "d.add(LeakyReLU())\n",
    "d.add(BatchNormalization())      \n",
    "d.add(ZeroPadding2D((2, 2)))\n",
    "\n",
    "d.add(Conv2D(8, (5,5), data_format='channels_first', padding='valid'))\n",
    "d.add(LeakyReLU())\n",
    "d.add(BatchNormalization())\n",
    "d.add(ZeroPadding2D((1, 1)))\n",
    "\n",
    "d.add(Conv2D(8, (5, 5), data_format='channels_first', padding='valid'))\n",
    "d.add(LeakyReLU())\n",
    "d.add(BatchNormalization())\n",
    "d.add(AveragePooling2D((2, 2)))\n",
    "d.add(Flatten())\n",
    "\n",
    "d.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "discriminator = d\n",
    "d.summary()\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create generator model\n",
    "\n",
    "We create then the generator model. The model takes as input a vector of size `latent_size` and then a combination of convolutional layers and upsampling to get at the end an output image of 25x25 size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Sequential(name='generator')\n",
    "\n",
    "gen.add(Dense(64 * 7, input_dim=latent_size))\n",
    "gen.add(Reshape((8, 7,8)))\n",
    "\n",
    "gen.add(Conv2D(64, (6, 8), data_format='channels_first', padding='same', kernel_initializer='he_uniform'))\n",
    "gen.add(LeakyReLU())\n",
    "gen.add(BatchNormalization())\n",
    "\n",
    "gen.add(UpSampling2D(size=(2, 2)))\n",
    "gen.add(ZeroPadding2D((2, 0)))\n",
    "\n",
    "gen.add(Conv2D(6, (5, 8), data_format='channels_first', kernel_initializer='he_uniform'))\n",
    "gen.add(LeakyReLU())\n",
    "gen.add(BatchNormalization())\n",
    "\n",
    "gen.add(UpSampling2D(size=(2, 3)))\n",
    "gen.add(ZeroPadding2D((0,3)))\n",
    "\n",
    "gen.add(Conv2D(6, (3, 8), data_format='channels_first', kernel_initializer='he_uniform'))\n",
    "gen.add(LeakyReLU())\n",
    "\n",
    "gen.add(Conv2D(1, (2, 2), data_format='channels_first', use_bias=False, kernel_initializer='glorot_normal'))\n",
    "gen.add(Activation('relu'))\n",
    "    \n",
    "generator = gen\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load initial weights\n",
    "\n",
    "Optionally we can load a initial set of weights for both discriminator and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in case we what to start an initial configuration\n",
    "if (load_initial_weights):\n",
    "    generator_weights = 'weights/generator_' + input_weights + '.h5'\n",
    "    discriminator_weights = 'weights/discriminator_' + input_weights + '.h5'\n",
    "    print('loading weight files:',generator_weights,discriminator_weights)\n",
    "    generator.load_weights(generator_weights)\n",
    "    discriminator.load_weights(discriminator_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile models\n",
    "\n",
    "Now we compile the previously defined models and we set the loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(optimizer=RMSprop(), loss='binary_crossentropy')\n",
    "\n",
    "generator.compile( optimizer=RMSprop(), loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make combined model\n",
    "\n",
    "Now we make the combined GAN model. It is a combination of the generator and the discriminator, since the input data are the random fake data which are processed first by the generator and then by the discriminator. In this combined model the discrimionator weights are considered fixed. \n",
    "For making the combined model we use the Keras Functional model building, since we use as input to the discriminator the output of the generator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = Input(shape=(latent_size, ), name='latent_input')\n",
    "\n",
    "fake_image = generator( latent)\n",
    "\n",
    "discriminator.trainable = False\n",
    "fake_disc_out = discriminator(fake_image)\n",
    "combined = Model(inputs=[latent], outputs=[fake_disc_out], name='combined_model')\n",
    "\n",
    "combined.compile( optimizer=RMSprop(), loss='binary_crossentropy')\n",
    "combined.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get input data\n",
    "\n",
    "We retrive now the input full simulated image data. The data consists of 2D 200,000 images with size 25x25. \n",
    "They are the x-z (transverse and longitudinal) projection of original 3D showers generated with full simulation (Geant4) of a high granumarity electromagnetic calorimteter detector prototype for CLIC, a future linear collider project. \n",
    "\n",
    "A reduced data set is available in the GitHub repository. The full dataset is available in CERNBox and if it cannot be accessed it can be downlowded from this link: https://cernbox.cern.ch/index.php/s/agKs8jEeYmPSPos\n",
    "\n",
    "A detailed explanation on the orifinal data is available in this publication, \n",
    "*F. Carminati, A. Gheata, K. Gulrukh, P. Mendez Lorenzo, S. Sharan, S. Vallecorsa, Three dimensional Generative Adversarial Networks for fast simulation. Journal of Physics: Conference Series. 1085. 032016. 10.1088/1742-6596/1085/3/032016*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### small data set is 10000 evts\n",
    "d=h5py.File(\"data/Electron2D_data.h5\",'r')\n",
    "\n",
    "# path to full data (200k events ~1Gb)\n",
    "#d = h5py.File(\"/eos/user/m/moneta/ml-data/Electron2D_data.h5\",'r')\n",
    "\n",
    "# the data consists of two items, the ECAL shower profile which is 200k x 1 x 25 x 25 and \n",
    "# the initial electron energy (name = 'target') that is a uniform distribution between [0,500] GeV. \n",
    "# we use only the ECAL shower profile and not the energy as input \n",
    "\n",
    "\n",
    "xd = d.get('ECAL')\n",
    "print(xd.shape)\n",
    "#e=d.get('target')\n",
    "#print(e.shape)\n",
    "\n",
    "\n",
    "print ('Number of events in file',xd.shape[0])\n",
    "\n",
    "nx = xd.shape[2]\n",
    "ny = xd.shape[3]\n",
    "print('image size is :',nx,' x ',ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert in input Numpy array\n",
    "# the shape of the input should be a 4-th array \n",
    "# as   nevents x 1 x width x depth\n",
    "X=np.array(xd[:nevt,:,:])\n",
    "\n",
    "print('*** Input data shape ***')\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Training and Test data\n",
    "\n",
    "we split here the input data in trainig and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unphysical values\n",
    "X[X < 1e-6] = 0\n",
    "\n",
    "# split in train and test data using the train_test_split function from sklearn\n",
    "X_train, X_test  = train_test_split(X, train_size= train_event_rate, random_state=seed)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "nb_train, nb_test = X_train.shape[0], X_test.shape[0]\n",
    "\n",
    "print('split input data in ',nb_train, 'train events and ',nb_test,'test events')\n",
    "\n",
    "#convert to float32\n",
    "\n",
    "X_train = X_train.astype(np.float32)  \n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "\n",
    "tot_epoch_done = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Training\n",
    "\n",
    "For the training of the GAN we define first some convenient functions that we will use later. \n",
    "The functions we define are: \n",
    "\n",
    "*  **generate_random_data** to generate the input data for the generator. We generate data from a normal distribution with  zero mean and a sigma that varies for each event with the value drawn from a uniform distribution in the range [1,5]\n",
    "\n",
    "*  **train_GAN_on batch** is a function performing a weights update using a batch of events (e.g. 100 events). It takes as input the original true data (the full simulated images) and using random data as input for the generator, it computes the loss functions first for the discriminator and then for the generator and update the weights using a gradient descent optimization algorithm.  \n",
    "\n",
    "*  **test_GAN** is a function that using the current update weights of the generator network returns the generated image data and also coputes the test loss functions using the statistically independent test input data set.\n",
    "\n",
    "* **train_GAN** is the function performing the full GAN training on the given number of epochs. It calls for each batch of events in an apoch the *train_GAN_on batch* function and then for each epoch tests the model state with the  *test_GAN* function. \n",
    "\n",
    "We also define a function **bit_flip** that is used to flip randomly some of the labels (e.g. 5%) for the discriminator. This is useful to avoid that the discriminator gets stuck (vanishing gradients) and its weights are  not updated anymore \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function *generate_random_data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate an array of n x input_size  random events for the generator input \n",
    "# we generate from a N(0,s) where s is from a uniform distribution in [1,5] \n",
    "def generate_random_data(n): \n",
    "    noise = np.random.normal(0, 1, (n, latent_size) ) \n",
    "    sampled_energies = np.random.uniform(1, 5, (n,1) )\n",
    "    random_data = np.multiply(sampled_energies, noise)\n",
    "    return random_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function **bit_flip** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bit_flip(x, prob=flip_rate):\n",
    "    \"\"\" flips a int array's values with some probability \"\"\"\n",
    "    x = np.array(x)\n",
    "    selection = np.random.uniform(0, 1, x.shape) < prob\n",
    "    x[selection] = 1 * np.logical_not(x[selection])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function *train_GAN_on_batch* \n",
    "\n",
    "Training of the GAN on a single batch. Please note the following tricks used commonly in order to better stabilize the training: \n",
    "\n",
    "*  The loss function for the generator to optimize is *max(log (D))* instead of *min(log (1-D))*. This formulation suffer less from vanishing gradients. \n",
    "*  Some of the labels are randomly flip with a low probability ( ~ 1%) when training the discriminator\n",
    "*  Train the discriminator on separate batches for real and fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GAN_on_batch(image_batch): \n",
    "    \n",
    "        #generate input random data for generator \n",
    "        generator_input = generate_random_data(batch_size)\n",
    "        \n",
    "        # perform generator prediction\n",
    "        generated_images = generator.predict(generator_input, verbose=False)\n",
    "\n",
    "        # train discriminator on real batch and fake batch \n",
    "        # important to do separatly\n",
    "        # real batch will have label 1 and fake label 0\n",
    "        # we use also a trick to flip randomly some small percentage of labels\n",
    "        \n",
    "        real_batch_loss = discriminator.train_on_batch(image_batch, bit_flip(np.ones(batch_size))) \n",
    "        fake_batch_loss = discriminator.train_on_batch(generated_images, bit_flip(np.zeros(batch_size))) \n",
    "  \n",
    "        # compute total discriminator loss \n",
    "        discriminator_loss = (real_batch_loss + fake_batch_loss)/2\n",
    "        \n",
    "        #x = np.concatenate((image_batch, generated_images))\n",
    "        #y = np.concatenate(( bit_flip(np.ones(batch_size) ), bit_flip(np.zeros(batch_size))  ) )\n",
    "        #discriminator_loss =  discriminator.train_on_batch(x, y )\n",
    "        \n",
    "        # do 2 training iteration on the generator\n",
    "        # to compensate we have trained discriminator two times\n",
    "        \n",
    "        gen_losses = []                                                       \n",
    "        for _   in range(2) :                                                    \n",
    "            #generate input random to generator\n",
    "            generator_input = generate_random_data(batch_size)\n",
    "\n",
    "            # train generator and compute its loss\n",
    "            gloss = combined.train_on_batch( generator_input, np.ones(batch_size))\n",
    "            gen_losses.append(gloss)\n",
    "        \n",
    "        #compute mean generator loss of all the losses we have obtained\n",
    "        generator_loss = np.mean(gen_losses)\n",
    "\n",
    "        return discriminator_loss, generator_loss\n",
    "                              \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function *test_GAN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function definining test of GAN that will be run for each single epoch\n",
    "def test_GAN(): \n",
    "    \n",
    "    # generate test random data for giving as input to the generator and \n",
    "    # use after to compute the discriminator loss\n",
    "    generator_input = generate_random_data(nb_test)\n",
    "    \n",
    "    # generate 'fake' images with generator\n",
    "    generated_images = generator.predict(generator_input, verbose=False)\n",
    "    #print('shape generated images',generated_images.shape)\n",
    "\n",
    "    # compute now discriminator loss from fake (label = 0) vs true (label = 1) images\n",
    "                              \n",
    "    X = np.concatenate((X_test, generated_images))\n",
    "    y = np.array([1] * nb_test + [0] * nb_test)                              \n",
    "    discriminator_test_loss = discriminator.evaluate(X, y, verbose=False, batch_size=batch_size)\n",
    "\n",
    "     \n",
    "    # we generate also some other random input data for computing the loss function for the generator\n",
    "    #  use 2 x data_size to have same statistics as for discriminator\n",
    "    generator_input = generate_random_data(2 * nb_test)  \n",
    "    # as labels we use 1 the value we input when training \n",
    "    y = np.ones(2 * nb_test)\n",
    "\n",
    "    generator_test_loss = combined.evaluate(generator_input, y, verbose=False, batch_size=batch_size)\n",
    "    \n",
    "    return discriminator_test_loss, generator_test_loss, generated_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function train_GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GAN(nepochs, fig_epoch): \n",
    "    #loop on number of epochs\n",
    "    for epoch in range(nepochs):\n",
    "        print('Epoch ',epoch + 1,' of ', nepochs)\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        \n",
    "        #use Keras progress bar for displaying progress in training\n",
    "        progress_bar = Progbar(target=nb_batches)\n",
    "\n",
    "        epoch_gen_loss = []\n",
    "        epoch_disc_loss = []\n",
    "        \n",
    "        #loop on the batches \n",
    "        for index in range(nb_batches):\n",
    "            progress_bar.update(index)\n",
    "                   \n",
    "            image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                    \n",
    "            discrim_loss, generator_loss = train_GAN_on_batch(image_batch)\n",
    "\n",
    "            # we save the losses\n",
    "            epoch_disc_loss.append(discrim_loss)\n",
    "            epoch_gen_loss.append( generator_loss )\n",
    "                              \n",
    "                          \n",
    "\n",
    "        # after all batch we compute mean of train losses\n",
    "    \n",
    "        discriminator_train_loss = np.mean(np.array(epoch_disc_loss), axis=0)\n",
    "        generator_train_loss = np.mean(np.array(epoch_gen_loss), axis=0)\n",
    "    \n",
    "        #### TESTING   \n",
    "        print('\\nTesting for epoch :' , epoch + 1)\n",
    "\n",
    "        discriminator_test_loss, generator_test_loss, X_gen = test_GAN()\n",
    "\n",
    "        print('generator  train and test loss', generator_train_loss, generator_test_loss)\n",
    "        print('discrimin. train and test loss', discriminator_train_loss, discriminator_test_loss)\n",
    "\n",
    "        train_loss.append([discriminator_train_loss, generator_train_loss])\n",
    "        test_loss.append([discriminator_test_loss, generator_test_loss])\n",
    "    \n",
    "\n",
    "        xdata.append(epoch+1)\n",
    "    \n",
    "        plot1.set_xdata(xdata)\n",
    "        plot2.set_xdata(xdata)\n",
    "        plot3.set_xdata(xdata)\n",
    "        plot4.set_xdata(xdata)\n",
    "    \n",
    "        plot1.set_ydata(np.array(train_loss)[:,0])\n",
    "        plot2.set_ydata(np.array(test_loss)[:,0])\n",
    "        plot3.set_ydata(np.array(train_loss)[:,1])\n",
    "        plot4.set_ydata(np.array(test_loss)[:,1])\n",
    "        \n",
    "        ax3.clear()\n",
    "        ax3.hist(np.sum(X_test,axis=(1,2,3)),50,range=(0,15))\n",
    "        ax3.hist(np.sum(X_gen,axis=(1,2,3)),50,range=(0,15))\n",
    "    \n",
    "        fig_epoch.canvas.draw()\n",
    "        \n",
    "        \n",
    "        \n",
    "        #end loop on epochs\n",
    "        \n",
    "    # return the generated images for testing\n",
    "    return X_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the GAN training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for interactive plotting in matplotlib\n",
    "plt.ion()\n",
    "fig_epoch = plt.figure(1)\n",
    "ax1 = fig_epoch.add_subplot(311)\n",
    "ax2 = fig_epoch.add_subplot(312)\n",
    "ax3 = fig_epoch.add_subplot(313)\n",
    "\n",
    "xdata =[]\n",
    "yy=[]\n",
    "ax1.set_xlim(0,nb_epochs+1)\n",
    "ax2.set_xlim(0,nb_epochs+1)\n",
    "ax1.set_ylim(0,5)\n",
    "ax2.set_ylim(0,5)\n",
    "plot1, = ax1.plot(xdata,yy,label=\"discriminator training loss\")\n",
    "plot2, = ax1.plot(xdata,yy,label=\"discriminator test loss\")\n",
    "ax1.legend()\n",
    "plot3, = ax2.plot(xdata,yy,label=\"generator training loss\")\n",
    "plot4, = ax2.plot(xdata,yy,label=\"generator test loss\")\n",
    "ax2.legend()\n",
    "\n",
    "\n",
    "ax3.hist(np.sum(X_test,axis=(1,2,3)),50,range=(0,15))\n",
    "\n",
    "plt.show()  \n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we perform the actual training by calling the train_GAN function\n",
    "###nb_epochs = 10\n",
    "X_gen = train_GAN(nb_epochs, fig_epoch)\n",
    "#update total number of epochs done for training\n",
    "tot_epoch_done = tot_epoch_done + nb_epochs\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the weights of the trained model\n",
    "\n",
    "we save the weights for the generator and the discriminator and counting the total number of epochs we have been used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights for discriminator and generator\n",
    "##tot_epoch_done = 999\n",
    "\n",
    "generator_weights_file = 'weights/generator_weights_epoch_'+ str(tot_epoch_done)+'.h5'\n",
    "discriminator_weights_file = 'weights/discriminator_weights_epoch_'+ str(tot_epoch_done)+'.h5'\n",
    "\n",
    "generator.save_weights(generator_weights_file, overwrite=True)\n",
    "discriminator.save_weights(discriminator_weights_file, overwrite=True)\n",
    "\n",
    "print('save weights of generator and discriminator in',generator_weights_file,'and',discriminator_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save also the loss function values\n",
    "loss_file = 'loss_function_values_epoch_' + str(tot_epoch_done) + '.npy'\n",
    "np.save(loss_file, np.concatenate((np.array(train_loss),np.array(test_loss)),axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model  and generate images\n",
    "\n",
    "Here we load the saved weights from the file and we generated new images data using the generator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator_weights_file = 'weights/generator_weights_epoch_90.h5'\n",
    "\n",
    "#load the generator weights from a file\n",
    "#generator.load_weights(generator_weights_file)\n",
    "\n",
    "#print('loaded generator weights file:',generator_weights_file)\n",
    "\n",
    "X_gen = generator.predict(generate_random_data(nb_test), verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the generated images\n",
    "\n",
    "Here we look at the generated images and we make some coomparison with the original (true) images of the same type \n",
    "that we have provided as input for the GAN. \n",
    "\n",
    "We make sample plot of the single and average image profile, and we look at their distributions in the two coordinates and also at the mean and spread (standard deviation) that we obtain\n",
    "\n",
    "As comparison we visualize the results either using matplotlib or (in case you have it installed) using the CERN data analysis software package, ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a single original (true) and a generated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make plot of generated images comparinig with true images\n",
    "# X_gen is generated X_test is true\n",
    "plt.figure(2)\n",
    "plt.subplot(121)\n",
    "print('shape of test data',X_test.shape)\n",
    "nx = X_test.shape[2]\n",
    "ny = X_test.shape[3]\n",
    "image_true = X_test[1,:].reshape(nx,ny)\n",
    "print('image shape ', image_true.shape)\n",
    "#plot images - note matplotlib uses matrix convention x axis matrix columnx, y axis matrix rowx\n",
    "\n",
    "plt.imshow(image_true, origin='lower',cmap=plt.cm.gist_ncar)\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "print('shape of gen data',X_gen.shape)\n",
    "image_gen = X_gen[1,:].reshape(nx,ny)\n",
    "\n",
    "plt.imshow(image_gen, origin='lower',cmap=plt.cm.gist_ncar)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('central image values true:\\n',image_true[11:14,11:14], '\\n generated:\\n',image_gen[11:14,11:14] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display average of the profile of all true and generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make plot of generated images comparinig with true images\n",
    "# X_gen is generated X_test is true\n",
    "plt.figure(3)\n",
    "plt.subplot(121)\n",
    "average_image_true = np.mean(X_test,axis=0).reshape(nx,ny)\n",
    "\n",
    "plt.imshow(average_image_true, origin='lower',cmap=plt.cm.gist_ncar)\n",
    "plt.ylabel('Transverse')\n",
    "plt.xlabel('Longitudinal')\n",
    "\n",
    "plt.subplot(122)\n",
    "average_image_gen = np.mean(X_gen,axis=0).reshape(nx,ny)\n",
    "plt.imshow(average_image_gen, interpolation='none',origin='lower',cmap=plt.cm.gist_ncar)\n",
    "plt.ylabel('Transverse')\n",
    "plt.xlabel('Longitudinal')\n",
    "plt.show()\n",
    "\n",
    "print('central image values true:\\n',average_image_true[11:14,11:14], '\\n generated:\\n',average_image_gen[11:14,11:14] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display image profiles in the transverse and longitudinal planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute projections summing on other axis (y for px and x for py)\n",
    "px_true = np.sum(X_test[:,0,:,:],axis=2)\n",
    "py_true = np.sum(X_test[:,0,:,:],axis=1)\n",
    "\n",
    "px_gen = np.sum(X_gen[:,0,:,:],axis=2)\n",
    "py_gen = np.sum(X_gen[:,0,:,:],axis=1)\n",
    "\n",
    "nevt = X_test.shape[0]\n",
    "nx = X_test.shape[2]\n",
    "ny = X_test.shape[3]\n",
    "xpos = np.array(range(0,nx))\n",
    "#make a vector of (nevt x nx) for positions \n",
    "vpos = np.tile(xpos,(nevt,1))\n",
    "\n",
    "n = nevt * nx\n",
    "plt.figure(5)\n",
    "plt.subplot(211)\n",
    "plt.hist(vpos.reshape(nevt*nx),bins=nx,weights=px_true.reshape(nevt*nx),label=\"real transverse\")\n",
    "plt.hist(vpos.reshape(nevt*nx),bins=nx,weights=px_gen.reshape(nevt*nx),label=\"gen transverse\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.hist(vpos.reshape(nevt*ny),bins=ny,weights=py_true.reshape(nevt*ny),label=\"real longitudinal\")\n",
    "plt.hist(vpos.reshape(nevt*ny),bins=ny,weights=py_gen.reshape(nevt*ny),label=\"gen longitudinal\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display total Energy for original and generated images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by summing the obtained projections we get the total values\n",
    "etot_true = np.sum(px_true, axis=1)\n",
    "etot_gen = np.sum(px_gen, axis=1)\n",
    "\n",
    "plt.figure(6)\n",
    "\n",
    "plt.hist(etot_true,50,range=(0,12),label=\"real energy\")\n",
    "\n",
    "#plt.subplot(212)\n",
    "plt.hist(etot_gen,50,range=(0,12),label=\"generated energy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute image statistics \n",
    "\n",
    "We compute for each image the mean position in the transverse and longitudial coordinates and the corresponding spread (standard deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to compute the statistics (weighted mean and weighted standard deviation)  \n",
    "def calculate_stats(values):\n",
    "    xpos = np.array(range(-12,13))\n",
    "    #make a vector of (nevt x 25) for positions \n",
    "    vpos = np.tile(xpos,(values.shape[0],1))\n",
    "    #compute average \n",
    "    mean = np.ma.average(vpos, weights=values, axis = 1)\n",
    "    #compute varince - need to make an array of means same shape as vpos (next x 25)\n",
    "    marray = np.tile(mean,(25,1)).transpose()\n",
    "    variance = np.ma.average((vpos-marray)**2, weights=values, axis=1)\n",
    "    stddev = np.sqrt(variance)\n",
    "    return mean,stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute also mean and standard deviation in the two directions\n",
    "\n",
    "meanx_true, stdx_true = calculate_stats(px_true)\n",
    "meany_true, stdy_true = calculate_stats(py_true)\n",
    "\n",
    "\n",
    "meanx_gen, stdx_gen = calculate_stats(px_gen)\n",
    "meany_gen, stdy_gen = calculate_stats(py_gen)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(7)\n",
    "plt.subplot(221)\n",
    "\n",
    "plt.hist(meanx_true,50,range=(-1,1),label='trans. mean (real)')\n",
    "#plt.title('mean X (true)')\n",
    "\n",
    "#plt.subplot(222)\n",
    "plt.hist(meanx_gen,50, range=(-1,1),label='trans. mean (gen)')\n",
    "plt.legend()\n",
    "#plt.title('mean X (gen)')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.hist(stdx_true,50,range=(0,3),label='trans. std (real)')\n",
    "#plt.title('std X (true)')         \n",
    "\n",
    "#plt.subplot(224)          \n",
    "plt.hist(stdx_gen,50, range=(0,3),label='trans. std (gen)')\n",
    "#plt.title('std X (gen)')\n",
    "plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "#plt.figure(0)\n",
    "plt.subplot(222)\n",
    "plt.hist(meany_true,50, range=(-5,5),label='long. mean (real)')\n",
    "#plt.title('mean Y (true)')          \n",
    "#plt.subplot(222)          \n",
    "plt.hist(meany_gen,50, range=(-5,5),label='long. mean (gen)')\n",
    "#plt.title('mean Y (gen)')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.hist(stdy_true,50,range=(0,8),label='long. std (real)')\n",
    "#plt.title('std Y (true)')         \n",
    "\n",
    "#plt.subplot(224)          \n",
    "plt.hist(stdy_gen,50,range=(0,8),label='long. std (gen)')\n",
    "#plt.title('std Y (gen)')\n",
    "plt.legend()\n",
    "          \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis using ROOT \n",
    "\n",
    "We visualize the image and their statistics using histograms from the CERN data analysis software package, ROOT\n",
    "\n",
    "First we book and fill histograms for the orginal (true) images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "\n",
    "htrueXY = ROOT.TH2D(\"htrue\",\"real shower profile\",25,0,25,25,0,25)\n",
    "htrueX = ROOT.TH1D(\"htruex\",\"real images\",25,0,25)\n",
    "htrueY = ROOT.TH1D(\"htruey\",\"real images\",25,0,25)\n",
    "htrueE = ROOT.TH1D(\"htrueE\",\"real energy\",50,0,12)\n",
    "\n",
    "#prepare the arrays for filling the histograms\n",
    "# note that we do using arrays to avoid performing loops in Python that is very slow\n",
    "\n",
    "xpos = np.array(range(0,25))\n",
    "xpos = xpos + 0.5\n",
    "xvec = np.tile(xpos,(25,1)).T\n",
    "xvec = xvec.reshape(25*25)\n",
    "print(xvec.shape,xvec[1:50])\n",
    "\n",
    "yvec = np.tile(xpos,(1,25))\n",
    "yvec = yvec.reshape(25*25)\n",
    "print(yvec.shape,yvec[1:50])\n",
    "\n",
    "nevts = X_test.shape[0]\n",
    "xvec = np.tile(xvec,(1,nevts))\n",
    "yvec = np.tile(yvec,(1,nevts))\n",
    "\n",
    "n = nevts * 25 * 25\n",
    "weights = np.array( X_test.reshape( n), dtype = np.float64)\n",
    "  \n",
    "xvec = xvec.reshape(n)\n",
    "yvec = yvec.reshape(n)\n",
    "\n",
    "\n",
    "print(weights.shape, xvec.shape, yvec.shape)\n",
    "\n",
    "# have transverse  vs longitudinal \n",
    "htrueXY.FillN(n,yvec, xvec, weights)\n",
    "htrueX.FillN(n, xvec, weights)\n",
    "htrueY.FillN(n, yvec, weights)\n",
    "\n",
    "etot = np.array( np.sum( X_test, axis=(2,3)), dtype = np.float64)\n",
    "etot_true = etot.reshape(nevts)\n",
    "print (etot_true.shape)\n",
    "weights = np.ones(nevts)\n",
    "htrueE.FillN(nevts, etot_true, weights)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book and fill histograms for the generated images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgenXY = ROOT.TH2D(\"htrue\",\"generated shower profile\",25,0,25,25,0,25)\n",
    "hgenX = ROOT.TH1D(\"htruex\",\"generated images\",25,0,25)\n",
    "hgenY = ROOT.TH1D(\"htruey\",\"generated images\",25,0,25)\n",
    "hgenE = ROOT.TH1D(\"htrueE\",\"generated energy\",50,0,12)\n",
    "\n",
    "\n",
    "weights = np.array( X_gen.reshape( n), dtype = np.float64)\n",
    "\n",
    "xvec = xvec.reshape(n)\n",
    "yvec = yvec.reshape(n)\n",
    "\n",
    "# have transverse  vs longitudinal \n",
    "hgenXY.FillN (n,yvec, xvec, weights)\n",
    "hgenX.FillN(n, xvec, weights)\n",
    "hgenY.FillN(n, yvec, weights)\n",
    "\n",
    "etot = np.array( np.sum( X_gen, axis=(2,3)), dtype = np.float64)\n",
    "etot_gen = etot.reshape(nevts)\n",
    "print (etot_gen.shape)\n",
    "weights = np.ones(nevts)\n",
    "hgenE.FillN(nevts, etot_gen, weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the Javascript visualization of ROOT histogram \n",
    "%jsroot on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIsplay image profile for all events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c = ROOT.TCanvas(\"c1\",\"\",1000,500)\n",
    "c.Divide(2,1)\n",
    "c.cd(1)\n",
    "\n",
    "maxval = max(htrueXY.GetMaximum(), hgenXY.GetMaximum())\n",
    "htrueXY.SetMaximum(maxval)\n",
    "htrueXY.Draw(\"COLZ\")\n",
    "\n",
    "c.cd(2)\n",
    "#set same scale as previous histogram                   \n",
    "hgenXY.SetMaximum(maxval)\n",
    "hgenXY.Draw(\"COLZ\")\n",
    "\n",
    "c.Draw()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIsplay image profile projections in the two coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cname = \"c2\"\n",
    "c = ROOT.TCanvas(\"c2\",\"\",1000,500)\n",
    "c.Divide(2,1)\n",
    "c1 = c.cd(1)\n",
    "\n",
    "hs1 = ROOT.THStack(\"hs1\",\"Transverse shower profile\")\n",
    "hs1.Add(htrueX)\n",
    "hs1.Add(hgenX)\n",
    "hgenX.SetLineColor(ROOT.kRed)\n",
    "hs1.Draw(\"hist nostack\")\n",
    "\n",
    "c1.BuildLegend()\n",
    "c1.SetLogy(1)\n",
    "\n",
    "c2 = c.cd(2)\n",
    "hs2 = ROOT.THStack(\"hs2\",\"Longitudinal shower profile\")\n",
    "hs2.Add(htrueY)\n",
    "hs2.Add(hgenY)\n",
    "hgenY.SetLineColor(ROOT.kRed)\n",
    "hs2.Draw(\"hist nostack\")\n",
    "\n",
    "c2.BuildLegend()\n",
    "c2.SetLogy(1)\n",
    "c.Draw()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_value_profX = htrueX.Chi2Test(hgenX,'CHI2/NDF')\n",
    "print('Transverse profile, Chi2/NDF = ',chi2_value_profX)\n",
    "\n",
    "chi2_value_profY = htrueY.Chi2Test(hgenY,'CHI2/NDF')\n",
    "print('Longitudinal profile, Chi2/NDF = ',chi2_value_profY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display total energy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ROOT.TCanvas()\n",
    "hs = ROOT.THStack(\"hs\",\"Total Deposited Energy\")\n",
    "hs.Add(htrueE)\n",
    "hgenE.SetLineColor(ROOT.kRed)\n",
    "hs.Add(hgenE)\n",
    "hs.Draw(\"hist nostack\")\n",
    "c.BuildLegend()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform a Chi2 test between the two generated histgogram to get a numerical value stating the quality of the agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_value = htrueE.Chi2Test(hgenE,'CHI2/NDF')\n",
    "print('Chi2/NDF = ',chi2_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
